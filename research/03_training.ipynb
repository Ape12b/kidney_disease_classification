{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows:\n",
    "\n",
    "1. Update config.yaml\n",
    "2. Update secrets.yaml [Optional]\n",
    "3. Update params.yaml\n",
    "4. Update the entity\n",
    "5. Update the configuration manager in src config\n",
    "6. Update the components\n",
    "7. Update the pipeline \n",
    "8. Update the main.py\n",
    "9. Update the dvc.yaml\n",
    "10. app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data_science\\kidney_disease_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\data_science\\kidney_disease_classification\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\data_science\\\\kidney_disease_classification'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass (frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "  root_dir: Path\n",
    "  trained_model_path: Path\n",
    "  updated_base_model_path: Path\n",
    "  training_data: Path\n",
    "  params_epochs: int\n",
    "  params_batch_size: int\n",
    "  params_is_augmentation: int\n",
    "  params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the configuration manager\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories# Placeholder content\n",
    "from cnnClassifier.entity.config_entity import DataIngestionConfig, PrepareBaseModelConfig\n",
    "import os\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_path = CONFIG_FILE_PATH,\n",
    "                 params_path = PARAMS_FILE_PATH,\n",
    "                 ):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def model_training_config(self) -> ModelTrainingConfig:\n",
    "        training =self.config.model_training\n",
    "        params = self.params\n",
    "        create_directories([training.root_dir])\n",
    "        \n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=training.root_dir,\n",
    "            trained_model_path=training.trained_model_path,\n",
    "            updated_base_model_path=self.config.prepare_base_model.updated_model_path,\n",
    "            training_data=os.path.join(self.config.data_ingestion.unzip_dir, 'kidney-ct-scan-image'),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "        \n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the components\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from cnnClassifier.entity.config_entity import ModelTrainingConfig\n",
    "\n",
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_ds(self):\n",
    "        img_height = self.config.params_image_size[:-1][0]\n",
    "        img_width = self.config.params_image_size[:-1][1]\n",
    "        img_size = (img_height, img_width)\n",
    "        \n",
    "        self.train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                self.config.training_data,\n",
    "                validation_split=0.2,\n",
    "                subset=\"training\",\n",
    "                seed=123,\n",
    "                image_size=img_size,\n",
    "                batch_size=self.config.params_batch_size)\n",
    "        \n",
    "        self.val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                self.config.training_data,\n",
    "                validation_split=0.2,\n",
    "                subset=\"validation\",\n",
    "                seed=123,\n",
    "                image_size=img_size,\n",
    "                batch_size=self.config.params_batch_size)\n",
    "        \n",
    "        # Optimizing\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "        self.train_ds = self.train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "        self.val_ds = self.val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        \n",
    "        \n",
    "        # Normalizing\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "        \n",
    "        self.train_ds = self.train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        self.val_ds = self.val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        \n",
    "        # Augmenting train dataset\n",
    "        data_augmentation = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.RandomFlip(\"horizontal\",\n",
    "                                input_shape=(img_height,\n",
    "                                            img_width,\n",
    "                                            3)),\n",
    "                tf.keras.layers.RandomRotation(0.1),\n",
    "                tf.keras.layers.RandomZoom(0.1),\n",
    "            ]\n",
    "            )\n",
    "        self.train_ds = self.train_ds.map(lambda x, y: (data_augmentation(x), y))             \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        self.model.summary()\n",
    "        self.model.fit(\n",
    "            self.train_ds,\n",
    "            epochs=self.config.params_epochs,\n",
    "            validation_data=self.val_ds\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-19 15:04:30,964: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-19 15:04:30,965: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "Found 465 files belonging to 2 classes.\n",
      "Using 372 files for training.\n",
      "Found 465 files belonging to 2 classes.\n",
      "Using 93 files for validation.\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "24/24 [==============================] - 17s 672ms/step - loss: 9.8470 - accuracy: 0.5108 - val_loss: 18.8406 - val_accuracy: 1.0000\n",
      "[2023-12-19 15:04:49,484: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "[2023-12-19 15:04:50,294: INFO: builder_impl: Assets written to: artifacts/model_training/model.hd5\\assets]\n",
      "[2023-12-19 15:04:50,323: INFO: 3780704459: Training pipeline succesful!]\n"
     ]
    }
   ],
   "source": [
    "# Updating pipeline\n",
    "from cnnClassifier.utils import logger\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.model_training_config()\n",
    "    model = ModelTraining(model_training_config)\n",
    "    model.get_base_model()\n",
    "    model.train_valid_ds()\n",
    "    model.train()\n",
    "    logger.info(f\"Training pipeline succesful!\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
