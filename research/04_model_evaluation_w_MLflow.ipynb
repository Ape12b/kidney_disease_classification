{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kidney Disease Classification using MLflow-DVC\n",
    "\n",
    "## Workflows:\n",
    "\n",
    "1. Update config.yaml\n",
    "2. Update secrets.yaml [Optional]\n",
    "3. Update params.yaml\n",
    "4. Update the entity\n",
    "5. Update the configuration manager in src config\n",
    "6. Update the components\n",
    "7. Update the pipeline \n",
    "8. Update the main.py\n",
    "9. Update the dvc.yaml\n",
    "10. app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\data_science\\\\kidney_disease_classification'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLFLOW_TRACKING_URI=https://dagshub.com/apri4u/kidney_disease_classification.mlflow \\\n",
    "MLFLOW_TRACKING_USERNAME=apri4u \\\n",
    "MLFLOW_TRACKING_PASSWORD=fded9025b0f1f046e473ab3a841fc37501954985 \\\n",
    "python script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/apri4u/kidney_disease_classification.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"apri4u\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"fded9025b0f1f046e473ab3a841fc37501954985\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"artifacts/model_training/model.hd5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass (frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating configuration\n",
    "\n",
    "import os\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories# Placeholder content\n",
    "from cnnClassifier.entity.config_entity import DataIngestionConfig, PrepareBaseModelConfig, ModelTrainingConfig, EvaluationConfig\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_path = CONFIG_FILE_PATH,\n",
    "                 params_path = PARAMS_FILE_PATH,\n",
    "                 ):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def model_evaluation_config(self) -> EvaluationConfig:\n",
    "        training =self.config.model_training\n",
    "        params = self.params\n",
    "        create_directories([training.root_dir])\n",
    "        \n",
    "        evaluation_config = EvaluationConfig(\n",
    "            path_of_model=os.path.join(\"artifacts\", \"model_training\", \"model.hd5\"),\n",
    "            training_data=os.path.join(\"artifacts\", \"data_ingestion\", \"raw\", \"kidney-ct-scan-image\"),\n",
    "            all_params=self.params,\n",
    "            mlflow_uri=\"https://dagshub.com/apri4u/kidney_disease_classification.mlflow\",\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components\n",
    "\n",
    "# Update the components\n",
    "from pathlib import Path\n",
    "from cnnClassifier.entity.config_entity import EvaluationConfig\n",
    "from cnnClassifier.utils.common import save_json\n",
    "import mlflow\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def _test_ds(self):\n",
    "        img_height = self.config.params_image_size[:-1][0]\n",
    "        img_width = self.config.params_image_size[:-1][1]\n",
    "        img_size = (img_height, img_width)\n",
    "        \n",
    "        self.test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                self.config.training_data,\n",
    "                validation_split=0.3,\n",
    "                subset=\"validation\",\n",
    "                seed=123,\n",
    "                image_size=img_size,\n",
    "                batch_size=self.config.params_batch_size)\n",
    "        \n",
    "        # Optimizing\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "        self.test_ds = self.test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "        \n",
    "        # Normalizing\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "        \n",
    "        self.test_ds = self.test_ds.map(lambda x, y: (normalization_layer(x), y))          \n",
    "        \n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._test_ds()\n",
    "        self.score = self.model.evaluate(self.test_ds)\n",
    "    \n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0],\n",
    "                  \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "    \n",
    "    def log_onto_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_uri_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\"loss\": self.score[0],\n",
    "                  \"accuracy\": self.score[1]})\n",
    "            \n",
    "            # Model registry won't work with filestorage\n",
    "            if tracking_uri_type_store != \"file\":\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.sklearn.log_model(\n",
    "                    self.model, \"model\", registered_model_name=\"VGG16_Model\"\n",
    "                )\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-19 18:44:23,514: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-19 18:44:23,515: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "Found 465 files belonging to 2 classes.\n",
      "Using 139 files for validation.\n",
      "9/9 [==============================] - 5s 517ms/step - loss: 0.0734 - accuracy: 0.5108\n",
      "[2023-12-19 18:44:28,881: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/19 18:44:32 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\apri4\\AppData\\Local\\Temp\\tmpbewzkqxw\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==1.3.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'VGG16_Model' already exists. Creating a new version of this model...\n",
      "2023/12/19 18:44:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16_Model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-19 18:44:41,128: INFO: 3735879283: Evaluation pipeline succesful!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'VGG16_Model'.\n"
     ]
    }
   ],
   "source": [
    "# Update the pipeline \n",
    "# Updating pipeline\n",
    "from cnnClassifier.utils import logger\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.model_evaluation_config()\n",
    "    model = ModelEvaluation(model_evaluation_config)\n",
    "    model.evaluation()\n",
    "    model.save_score()\n",
    "    model.log_onto_mlflow()\n",
    "    logger.info(f\"Evaluation pipeline succesful!\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
